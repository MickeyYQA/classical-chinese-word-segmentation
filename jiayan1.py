from jiayan import load_lm
from jiayan import CharHMMTokenizer

text = '北冥有鱼其名为鲲鲲之大不知其几千里也化而为鸟其名为鹏鹏之背不知其几千里也怒而飞其翼若垂天之云是鸟也海运则将徙于南冥南冥者天池也齐谐者志怪者也谐之言曰鹏之徙于南冥也水击三千里抟扶摇而上者九万里去以六月息者也'

lm = load_lm('jiayan.klm')
tokenizer = CharHMMTokenizer(lm)
print(list(tokenizer.tokenize(text)))

# 分词模型。结果：
# ['北', '冥', '有', '鱼', '其', '名', '为', '鲲', '鲲', '之', '大', '不', '知', '其', '几', '千里', '也', '化', '而', '为', '鸟', '其', '名', '为', '鹏', '鹏', '之', '背', '不', '知', '其', '几', '千里', '也', '怒', '而', '飞', '其', '翼', '若', '垂天', '之', '云', '是', '鸟', '也', '海运', '则', '将', '徙', '于', '南', '冥', '南', '冥', '者', '天池', '也', '齐谐', '者', '志怪', '者', '也', '谐', '之', '言', '曰', '鹏', '之', '徙', '于', '南', '冥', '也', '水', '击', '三', '千里', '抟扶摇', '而', '上', '者', '九', '万里', '去', '以', '六月', '息', '者', '也']